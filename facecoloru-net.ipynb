{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport torch\nimport os\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision.transforms import transforms\nclass CelebDataset(Dataset):\n    def __init__(self,root_dir,inp_size,dataset_size,transforms=None):\n        self.root_dir=root_dir\n        self.inp_size=inp_size\n        self.transforms=transforms\n        self.dataset_size=dataset_size\n        \n    def __len__(self):\n        return len(os.listdir(self.root_dir)[:self.dataset_size])\n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx=idx.tolist()\n\n        img_name=os.path.join(self.root_dir,os.listdir(self.root_dir)[:self.dataset_size][idx])\n        color=img_to_array(load_img(img_name,target_size=(216,216,3)))\n        bw=img_to_array(load_img(img_name,target_size=(self.inp_size[0],self.inp_size[1]),color_mode='grayscale'))\n        sample={'color': color, 'bw': bw}\n        \n        if self.transforms:\n            sample=self.transforms(sample)\n            \n        return sample\n    \nclass ToTensor(object):\n    def __call__(self, sample):\n        color, bw = sample['color'], sample['bw']\n        bw=np.transpose(bw,(2,0,1))\n        return {'bw': torch.tensor(bw).cuda(),'color': torch.tensor(color,dtype=torch.long).cuda()}\n    \ntransforms=transforms.Compose([ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        \n        self.conv1=nn.Conv2d(in_channels=1,out_channels=64,kernel_size=3)\n        self.batchn1=nn.BatchNorm2d(num_features=64)\n        self.relu1=nn.ReLU(inplace=True)\n        \n        self.conv2=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n        self.batchn2=nn.BatchNorm2d(num_features=64)\n        self.relu2=nn.ReLU(inplace=True)\n        \n        self.down1=nn.Conv2d(in_channels=64,out_channels=1,kernel_size=2,stride=2)\n        '''\n        self.conv3=nn.Conv2d(in_channels=1,out_channels=128,kernel_size=3)\n        self.batchn3=nn.BatchNorm2d(num_features=128)\n        self.relu3=nn.ReLU(inplace=True)\n        \n        self.conv4=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3)\n        self.batchn4=nn.BatchNorm2d(num_features=128)\n        self.relu4=nn.ReLU(inplace=True)\n        \n        self.down2=nn.Conv2d(in_channels=128,out_channels=1,kernel_size=2,stride=2)\n        '''\n        self.conv5=nn.Conv2d(in_channels=1,out_channels=256,kernel_size=3)\n        self.batchn5=nn.BatchNorm2d(num_features=256)\n        self.relu5=nn.ReLU(inplace=True)\n        \n        self.conv6=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3)\n        self.batchn6=nn.BatchNorm2d(num_features=256)\n        self.relu6=nn.ReLU(inplace=True)\n        \n        self.down3=nn.Conv2d(in_channels=256,out_channels=1,kernel_size=2,stride=2)\n        '''\n        self.conv7=nn.Conv2d(in_channels=1,out_channels=512,kernel_size=3)\n        self.batchn7=nn.BatchNorm2d(num_features=512)\n        self.relu7=nn.ReLU(inplace=True)\n        \n        self.conv8=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3)\n        self.batchn8=nn.BatchNorm2d(num_features=512)\n        self.relu8=nn.ReLU(inplace=True)\n        \n        self.down4=nn.Conv2d(in_channels=512,out_channels=1,kernel_size=2,stride=2)\n        '''\n        self.conv9=nn.Conv2d(in_channels=1,out_channels=1024,kernel_size=3)\n        self.batchn9=nn.BatchNorm2d(num_features=1024)\n        self.relu9=nn.ReLU(inplace=True)\n        \n        self.conv10=nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=3)\n        self.batchn10=nn.BatchNorm2d(num_features=1024)\n        self.relu10=nn.ReLU(inplace=True)\n        '''\n        self.up1=nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n        \n        self.conv11=nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=3)\n        self.batchn11=nn.BatchNorm2d(num_features=512)\n        self.relu11=nn.ReLU(inplace=True)\n        \n        self.conv12=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3)\n        self.batchn12=nn.BatchNorm2d(num_features=512)\n        self.relu12=nn.ReLU(inplace=True)\n        '''\n        self.up2=nn.ConvTranspose2d(in_channels=1024,out_channels=256,kernel_size=2,stride=2)#1024,512\n        \n        self.conv13=nn.Conv2d(in_channels=512,out_channels=256,kernel_size=3)\n        self.batchn13=nn.BatchNorm2d(num_features=256)\n        self.relu13=nn.ReLU(inplace=True)\n        \n        self.conv14=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3)\n        self.batchn14=nn.BatchNorm2d(num_features=256)\n        self.relu14=nn.ReLU(inplace=True)\n        '''\n        self.up3=nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n        \n        self.conv15=nn.Conv2d(in_channels=256,out_channels=128,kernel_size=3)\n        self.batchn15=nn.BatchNorm2d(num_features=128)\n        self.relu15=nn.ReLU(inplace=True)\n        \n        self.conv16=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3)\n        self.batchn16=nn.BatchNorm2d(num_features=128)\n        self.relu16=nn.ReLU(inplace=True)\n        '''\n        self.up4=nn.ConvTranspose2d(in_channels=256,out_channels=64,kernel_size=2,stride=2)#256,128\n        \n        self.conv17=nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3)\n        self.batchn17=nn.BatchNorm2d(num_features=64)\n        self.relu17=nn.ReLU(inplace=True)\n        \n        self.conv18=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n        self.batchn18=nn.BatchNorm2d(num_features=64)\n        self.relu18=nn.ReLU(inplace=True)\n        \n        self.outR=nn.Conv2d(in_channels=64,out_channels=256,kernel_size=1)\n        self.outG=nn.Conv2d(in_channels=64,out_channels=256,kernel_size=1)\n        self.outB=nn.Conv2d(in_channels=64,out_channels=256,kernel_size=1)\n        \n    def forward(self,t):\n        \n        t=self.conv1(t)\n        t=self.batchn1(t)\n        t=self.relu1(t)\n        \n        t=self.conv2(t)\n        t=self.batchn2(t)\n        c1=self.relu2(t)\n        \n        t=self.down1(c1)\n        '''\n        t=self.conv3(t)\n        t=self.batchn3(t)\n        t=self.relu3(t)\n        \n        t=self.conv4(t)\n        t=self.batchn4(t)\n        c2=self.relu4(t)\n        \n        t=self.down2(c2)\n        '''\n        t=self.conv5(t)\n        t=self.batchn5(t)\n        t=self.relu5(t)\n        \n        t=self.conv6(t)\n        t=self.batchn6(t)\n        c3=self.relu6(t)\n        \n        t=self.down3(c3)\n        '''\n        t=self.conv7(t)\n        t=self.batchn7(t)\n        t=self.relu7(t)\n        \n        t=self.conv8(t)\n        t=self.batchn8(t)\n        c4=self.relu8(t)\n        \n        t=self.down4(c4)\n        '''\n        t=self.conv9(t)\n        t=self.batchn9(t)\n        t=self.relu9(t)\n        \n        t=self.conv10(t)\n        t=self.batchn10(t)\n        t=self.relu10(t)\n        '''\n        t=self.up1(t)\n        c4=c4[:,:,4:20,4:20]\n        t=torch.cat((t,c4),dim=1)\n        \n        t=self.conv11(t)\n        t=self.batchn11(t)\n        t=self.relu11(t)\n        \n        t=self.conv12(t)\n        t=self.batchn12(t)\n        t=self.relu12(t)\n        '''\n        t=self.up2(t)\n        \n        c3=c3[:,:,4:118,4:118]  #40,118  16,4\n        t=torch.cat((t,c3),dim=1)\n        \n        t=self.conv13(t)\n        t=self.batchn13(t)\n        t=self.relu13(t)\n        \n        t=self.conv14(t)\n        t=self.batchn14(t)\n        t=self.relu14(t)\n        '''\n        t=self.up3(t)\n        c2=c2[:,:,41:81,41:81]\n        t=torch.cat((t,c2),dim=1)\n        \n        t=self.conv15(t)\n        t=self.batchn15(t)\n        t=self.relu15(t)\n        \n        t=self.conv16(t)\n        t=self.batchn16(t)\n        t=self.relu16(t)\n        '''\n        t=self.up4(t)\n        \n        c1=c1[:,:,16:236,16:236]  #16,90  162,236\n        t=torch.cat((t,c1),dim=1)\n        \n        t=self.conv17(t)\n        t=self.batchn17(t)\n        t=self.relu17(t)\n        \n        t=self.conv18(t)\n        t=self.batchn18(t)\n        t=self.relu18(t)\n        \n        R=self.outR(t)\n        G=self.outG(t)\n        B=self.outB(t)\n        \n        return R,G,B\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import optim\n\ndevice = torch.device(\"cuda\")\ncolor_model=Network()\ncolor_model.load_state_dict(torch.load('/kaggle/input/umodels/UNET_Pytorch.pkl',map_location=\"cuda:0\"),strict=False)\ncolor_model.to(device)\ncolor_model.eval()\n\nEPOCHS=200\nBATCH_SIZE=18\nLEARNING_RATE=0.00001\noptimizer=optim.Adam(color_model.parameters(), lr=LEARNING_RATE)\nceleb_dataset=CelebDataset(root_dir='/kaggle/input/celebrities-100k/100k/100k',inp_size=(256,256,3),dataset_size=100000,transforms=transforms)\nceleb_dataloader=DataLoader(celeb_dataset,batch_size=BATCH_SIZE,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for epoch in range(EPOCHS):\n    epoch_loss=0\n    for i,sample in enumerate(celeb_dataloader):\n        X,y=sample['bw'],sample['color']\n        R,G,B=color_model(X)\n        optimizer.zero_grad()\n        \n        Rloss=F.cross_entropy(R,y[:,:,:,0])\n        Gloss=F.cross_entropy(G,y[:,:,:,1])\n        Bloss=F.cross_entropy(B,y[:,:,:,2])\n        \n        loss=Rloss+Gloss+Bloss\n        epoch_loss+=loss.item()/BATCH_SIZE\n        \n        loss.backward()\n        optimizer.step()\n        if(i%100==0):\n            print(i,' : ',loss.item(),sep='')\n    \n    print('        Epoch: {0}, Loss: {1}'.format(epoch,epoch_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(color_model.state_dict(),'/kaggle/working/UNET_Pytorch.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nimport cv2\nfrom PIL import Image\nfrom skimage import data, color, io\ndef get_color_img(color_model,n_samples):\n    dataset=CelebDataset(root_dir='/kaggle/input/celebrities-100k/100k/100k',inp_size=(216,216,3),dataset_size=1000,transforms=transforms)\n    dataloader=DataLoader(celeb_dataset,batch_size=n_samples)\n    plotdata=DataLoader(dataset,batch_size=n_samples)\n    \n    samples=iter(dataloader)\n    sample=next(samples)\n    \n    plot_samples=iter(plotdata)\n    plot_sample=next(plot_samples)\n    \n    X,y=sample['bw'],sample['color']\n    R,G,B=color_model(X)\n    \n    R=np.expand_dims(torch.argmax(nn.Softmax(dim=1)(R),dim=1).cpu().numpy(),axis=1)\n    G=np.expand_dims(torch.argmax(nn.Softmax(dim=1)(G),dim=1).cpu().numpy(),axis=1)\n    B=np.expand_dims(torch.argmax(nn.Softmax(dim=1)(B),dim=1).cpu().numpy(),axis=1)\n    \n    y_pred=np.array(np.transpose(np.concatenate((R,G,B),axis=1),(0,2,3,1)),dtype=np.int32)\n                \n    X=X.cpu()\n    y=y.cpu()\n    \n    plt.figure(figsize=(15,15))\n    for i in range(n_samples):\n        plt.subplot(1,n_samples,i+1)\n        plt.imshow(X[i][0],cmap='gray')\n    plt.show()\n    \n    plt.figure(figsize=(15,15))\n    for i in range(n_samples):\n        plt.subplot(1,n_samples,i+1)\n        plt.imshow(y[i])\n    plt.show()\n    v=np.expand_dims(plot_sample['bw'].cpu().numpy(),axis=-1)\n    return y_pred,np.array(np.concatenate((v,v,v),axis=-1),dtype=np.int32)\n    \n    \nsamples,X=get_color_img(color_model,4)\nfig=plt.figure(figsize=(15,15))\nfor i in range(samples.shape[0]):\n    plt.subplot(1,samples.shape[0],i+1)\n    b=samples[i]/255\n    plt.imshow(b+X[i][0]/1000)\nplt.savefig('/kaggle/working/demo.jpg')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}